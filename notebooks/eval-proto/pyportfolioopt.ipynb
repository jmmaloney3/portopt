{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See https://pypi.org/project/pyportfolioopt/#a-quick-example\n",
    "import pandas as pd\n",
    "from pypfopt import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import expected_returns\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "# Read in price data\n",
    "df = pd.read_csv(\"../data/pyportfolioopt/stock_prices.csv\", parse_dates=True, index_col=\"date\")\n",
    "\n",
    "tickers = [\"MSFT\", \"AMZN\", \"KO\", \"MA\", \"COST\", \n",
    "           \"LUV\", \"XOM\", \"PFE\", \"JPM\", \"UNH\", \n",
    "           \"ACN\", \"DIS\", \"GILD\", \"F\", \"TSLA\"] \n",
    "df = yf.download(tickers, period=\"max\",auto_adjust=False)['Adj Close'].loc[\"1990\":]\n",
    "\n",
    "df = df.dropna(axis=0, how='any')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate expected returns and sample covariance\n",
    "mu = expected_returns.mean_historical_return(df)\n",
    "S = risk_models.sample_cov(df)\n",
    "\n",
    "# Remove any assets with infinite or NaN returns\n",
    "valid_assets = ~(np.isinf(mu) | np.isnan(mu))\n",
    "mu = mu[valid_assets]\n",
    "S = S.loc[valid_assets, valid_assets]\n",
    "\n",
    "# Check if we have valid data\n",
    "if len(mu) > 0 and not np.any(np.isnan(S)):\n",
    "    # Optimize for maximal Sharpe ratio\n",
    "    ef = EfficientFrontier(mu, S)\n",
    "    raw_weights = ef.max_sharpe()\n",
    "    cleaned_weights = ef.clean_weights()\n",
    "    # ef.save_weights_to_file(\"weights.csv\")  # saves to file\n",
    "    print(cleaned_weights)\n",
    "    ef.portfolio_performance(verbose=True)\n",
    "else:\n",
    "    print(\"Not enough valid data for optimization\")\n",
    "\n",
    "# Convert OrderedDict to DataFrame\n",
    "weights_df = pd.DataFrame.from_dict(cleaned_weights, orient='index', columns=['Weight'])\n",
    "weights_df.index.name = 'Ticker'\n",
    "weights_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypfopt.discrete_allocation import DiscreteAllocation, get_latest_prices\n",
    "\n",
    "latest_prices = get_latest_prices(df)\n",
    "\n",
    "da = DiscreteAllocation(cleaned_weights, latest_prices, total_portfolio_value=100000)\n",
    "allocation, leftover = da.greedy_portfolio()\n",
    "allocation_df = pd.DataFrame.from_dict(allocation, orient='index', columns=['Shares'])\n",
    "allocation_df.index.name = 'Ticker'\n",
    "print(\"Discrete allocation:\\n\", allocation_df)\n",
    "print(\"Funds remaining: ${:.2f}\".format(leftover))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/robertmartin8/PyPortfolioOpt/blob/master/cookbook/1-RiskReturnModels.ipynb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pypfopt\n",
    "from pypfopt import risk_models, expected_returns, plotting\n",
    "pypfopt.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells preprocess the data to prepare it for risk model evaluation.  The following\n",
    "steps are taken:\n",
    "1. Check for stationarity using ADF and KPSS tests\n",
    "2. If the data is non-stationary, plot the data to see if it has a trend, seasonal component, or cyclic component\n",
    "3. If the data has a trend, remove the trend\n",
    "4. If the data has a seasonal component, remove the seasonal component\n",
    "5. If the data has a cyclic component, remove the cyclic component\n",
    "6. After applying transformations, check to see if the data is stationary\n",
    "7. If the transformations were successful, standardize the data\n",
    "8. Evaluate the risk models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the data is non-stationary, plot the data to see\n",
    "# if any of the following conditions exist:\n",
    "# 1. the data has a trend\n",
    "# 2. the data has a seasonal component\n",
    "# 3. the data has a cyclic component\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Set up the plot style\n",
    "#plt.style.use('seaborn')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "def analyze_time_series(df, ticker):\n",
    "    # Create figure with subplots\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # 1. Original Time Series Plot (shows trend and cycles)\n",
    "    df[ticker].plot(ax=ax1, title=f'{ticker} Price Over Time')\n",
    "    ax1.set_xlabel('Date')\n",
    "    ax1.set_ylabel('Price')\n",
    "    \n",
    "    # 2. Seasonal Decomposition\n",
    "    decomposition = seasonal_decompose(df[ticker], period=252)  # 252 trading days in a year\n",
    "    decomposition.trend.plot(ax=ax2, title=f'{ticker} Trend')\n",
    "    ax2.set_xlabel('Date')\n",
    "    ax2.set_ylabel('Trend')\n",
    "    \n",
    "    # 3. Returns Distribution (helps identify heteroscedasticity)\n",
    "    returns = df[ticker].pct_change().dropna()\n",
    "    returns.plot(ax=ax3, title=f'{ticker} Returns Over Time')\n",
    "    ax3.set_xlabel('Date')\n",
    "    ax3.set_ylabel('Returns')\n",
    "    \n",
    "    # 4. Rolling Volatility (another view of heteroscedasticity)\n",
    "    rolling_std = returns.rolling(window=30).std()\n",
    "    rolling_std.plot(ax=ax4, title=f'{ticker} 30-Day Rolling Volatility')\n",
    "    ax4.set_xlabel('Date')\n",
    "    ax4.set_ylabel('Volatility')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot for each ticker or selected tickers\n",
    "#for ticker in df.columns[:3]:  # First 3 tickers as example\n",
    "for ticker in ['COST','JPM','MSFT']:  # First 3 tickers as example\n",
    "    analyze_time_series(df, ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with differencing the data and see if that makes the data stationary\n",
    "df_diff = df.diff().dropna()\n",
    "\n",
    "results = test_stationarity(df_diff)\n",
    "print(results.to_string(float_format=lambda x: '%.6f' % x if isinstance(x, float) else x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigate the differenced data for each ticker\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "ticker = 'AMZN'\n",
    "\n",
    "# Analyze original and differenced data for ticker\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Original price series\n",
    "df[ticker].plot(ax=ax1, title=f'{ticker} Original Price Series')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Price')\n",
    "\n",
    "# Differenced series\n",
    "df_diff[ticker].plot(ax=ax2, title=f'{ticker} Differenced Series')\n",
    "ax2.set_xlabel('Date')\n",
    "ax2.set_ylabel('Price Change')\n",
    "\n",
    "# Returns volatility\n",
    "returns = df_diff[ticker]\n",
    "rolling_std = returns.rolling(window=30).std()\n",
    "rolling_std.plot(ax=ax3, title='30-Day Rolling Volatility')\n",
    "ax3.set_xlabel('Date')\n",
    "ax3.set_ylabel('Volatility')\n",
    "\n",
    "# ACF plot of differenced series\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "plot_acf(df_diff[ticker].dropna(), ax=ax4, title=f'Autocorrelation of {ticker} Differenced Series')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed statistics\n",
    "print(f\"\\nADF Test Results for {ticker}:\")\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "adf_result = adfuller(df_diff[ticker].dropna())\n",
    "print(f'ADF Statistic: {adf_result[0]}')\n",
    "print(f'p-value: {adf_result[1]}')\n",
    "print('Critical values:')\n",
    "for key, value in adf_result[4].items():\n",
    "    print(f'\\t{key}: {value}')\n",
    "\n",
    "print(f\"\\nKPSS Test Results for {ticker}:\")\n",
    "from statsmodels.tsa.stattools import kpss\n",
    "kpss_result = kpss(df_diff[ticker].dropna(), regression='c')\n",
    "print(f'KPSS Statistic: {kpss_result[0]}')\n",
    "print(f'p-value: {kpss_result[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare relative changes\n",
    "amzn_rel_vol = df_diff['AMZN'].std() / df_diff['AMZN'].mean()\n",
    "cost_rel_vol = df_diff['COST'].std() / df_diff['COST'].mean()\n",
    "print(f\"AMZN relative volatility: {amzn_rel_vol}\")\n",
    "print(f\"COST relative volatility: {cost_rel_vol}\")\n",
    "\n",
    "# Look at actual test statistics, not just pass/fail\n",
    "for ticker in ['AMZN', 'COST']:\n",
    "    series = df_diff[ticker].dropna()\n",
    "    adf_stat, adf_pval, _, _, _, _ = adfuller(series)\n",
    "    kpss_stat, kpss_pval, _, _ = kpss(series, regression='c')\n",
    "    print(f\"\\n{ticker}:\")\n",
    "    print(f\"ADF p-value: {adf_pval:.6f}\")\n",
    "    print(f\"KPSS p-value: {kpss_pval:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try soem different transformations of the data and \n",
    "# see if that makes the data stationary\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "\n",
    "def test_and_plot_transformation(data, title, ax):\n",
    "    \"\"\"Test stationarity and plot the transformed data\"\"\"\n",
    "    # Remove any NaN values\n",
    "    clean_data = data.dropna()\n",
    "    \n",
    "    # Run tests\n",
    "    adf_stat, adf_pval, _, _, _, _ = adfuller(clean_data)\n",
    "    kpss_stat, kpss_pval, _, _ = kpss(clean_data, regression='c')\n",
    "    is_stationary = (adf_pval < 0.05) and (kpss_pval > 0.05)\n",
    "    \n",
    "    # Plot\n",
    "    clean_data.plot(ax=ax)\n",
    "    ax.set_title(f\"{title}\\nADF p-value: {adf_pval:.6f}\\nKPSS p-value: {kpss_pval:.6f}\\nStationary: {is_stationary}\")\n",
    "    ax.set_xlabel('Date')\n",
    "    \n",
    "    return is_stationary, adf_pval, kpss_pval\n",
    "\n",
    "# Set ticker to analyze\n",
    "ticker = 'COST'\n",
    "\n",
    "# Create figure\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Simple difference (baseline)\n",
    "diff = df[ticker].diff()\n",
    "test_and_plot_transformation(diff, f'{ticker} Simple Difference', ax1)\n",
    "\n",
    "# 2. Log returns\n",
    "log_returns = np.log(df[ticker]).diff()\n",
    "test_and_plot_transformation(log_returns, f'{ticker} Log Returns', ax2)\n",
    "\n",
    "# 3. Percentage change\n",
    "pct_change = df[ticker].pct_change()\n",
    "test_and_plot_transformation(pct_change, f'{ticker} Percentage Change', ax3)\n",
    "\n",
    "# 4. Standardized difference (difference divided by rolling std)\n",
    "roll_std = df[ticker].rolling(window=30).std()\n",
    "std_diff = df[ticker].diff() / roll_std\n",
    "test_and_plot_transformation(std_diff, f'{ticker} Standardized Difference', ax4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed results\n",
    "transformations = {\n",
    "    'Simple Difference': diff,\n",
    "    'Log Returns': log_returns,\n",
    "    'Percentage Change': pct_change,\n",
    "    'Standardized Difference': std_diff\n",
    "}\n",
    "\n",
    "print(f\"\\nDetailed Results for {ticker}:\")\n",
    "print(\"-\" * 50)\n",
    "for name, data in transformations.items():\n",
    "    clean_data = data.dropna()\n",
    "    adf_stat, adf_pval, _, _, _, _ = adfuller(clean_data)\n",
    "    kpss_stat, kpss_pval, _, _ = kpss(clean_data, regression='c')\n",
    "    is_stationary = (adf_pval < 0.05) and (kpss_pval > 0.05)\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"ADF p-value:  {adf_pval:.6f}\")\n",
    "    print(f\"KPSS p-value: {kpss_pval:.6f}\")\n",
    "    print(f\"Stationary:   {is_stationary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next try taking the log of the data and see if that makes the data stationary\n",
    "df_log = np.log(df)\n",
    "\n",
    "results = test_stationarity(df_log)\n",
    "print(results.to_string(float_format=lambda x: '%.6f' % x if isinstance(x, float) else x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next try detrending the data and see if that makes the data stationary    \n",
    "from scipy import stats\n",
    "\n",
    "def detrend_data(df):\n",
    "    \"\"\"\n",
    "    Detrend each column in the dataframe using linear regression.\n",
    "    \n",
    "    Args:\n",
    "        df: pandas DataFrame with time series data\n",
    "        \n",
    "    Returns:\n",
    "        pandas DataFrame with detrended data\n",
    "    \"\"\"\n",
    "    # Create time index for regression (0 to n-1)\n",
    "    time = np.arange(len(df))\n",
    "    \n",
    "    # Create DataFrame for detrended data\n",
    "    df_detrend = pd.DataFrame(index=df.index, columns=df.columns)\n",
    "    \n",
    "    # Detrend each column\n",
    "    for column in df.columns:\n",
    "        # Fit linear trend\n",
    "        slope, intercept, _, _, _ = stats.linregress(time, df[column])\n",
    "        \n",
    "        # Calculate trend\n",
    "        trend = slope * time + intercept\n",
    "        \n",
    "        # Remove trend\n",
    "        df_detrend[column] = df[column] - trend\n",
    "    \n",
    "    return df_detrend\n",
    "\n",
    "# Apply detrending\n",
    "df_detrend = detrend_data(df)\n",
    "\n",
    "# Test for stationarity\n",
    "results = test_stationarity(df_detrend)\n",
    "print(results.to_string(float_format=lambda x: '%.6f' % x if isinstance(x, float) else x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in price data\n",
    "past_df, future_df = df.iloc[:-250], df.iloc[-250:]\n",
    "\n",
    "future_cov = risk_models.sample_cov(future_df)\n",
    "sample_cov = risk_models.sample_cov(past_df)\n",
    "\n",
    "#plotting.plot_covariance(sample_cov, plot_correlation=True)\n",
    "#plotting.plot_covariance(future_cov, plot_correlation=True)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_methods = [\n",
    "    \"sample_cov\",\n",
    "    \"semicovariance\",\n",
    "    \"exp_cov\",\n",
    "    \"ledoit_wolf\",\n",
    "    \"ledoit_wolf_constant_variance\",\n",
    "    \"ledoit_wolf_single_factor\",\n",
    "    \"ledoit_wolf_constant_correlation\",\n",
    "    \"oracle_approximating\",\n",
    "]\n",
    "\n",
    "# Calculate future variance\n",
    "future_variance = np.diag(future_cov)\n",
    "\n",
    "# Create empty DataFrame with risk methods as index\n",
    "results_df = pd.DataFrame(index=risk_methods, columns=['Mean Abs Error'])\n",
    "\n",
    "for method in risk_methods:\n",
    "    S = risk_models.risk_matrix(past_df, method=method)\n",
    "    variance = np.diag(S)\n",
    "    results_df.loc[method, 'Mean Abs Error'] = np.sum(np.abs(variance - future_variance)) / len(variance)\n",
    "\n",
    "# Sort by error (optional)\n",
    "results_df = results_df.sort_values('Mean Abs Error', ascending=True)\n",
    "\n",
    "# Display results - with 6 decimal places\n",
    "print(results_df.to_string(float_format=lambda x: '%.6f' % x))\n",
    "\n",
    "# Plot results (optional)\n",
    "results_df.plot(kind='barh')\n",
    "plt.gca().invert_yaxis()  # Invert the y-axis to match DataFrame order\n",
    "plt.title('Mean Absolute Error in Predicting Future Variance')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Portfolio Optimization",
   "language": "python",
   "name": "portopt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
