{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-Pass CSV Reading Test\n",
    "Testing an approach to handle multi-line CSV fields while preserving header/footer handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0357e31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f8fcd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_csv_commas(line):\n",
    "    \"\"\"Count commas that separate CSV fields, using pandas to handle quoted fields\n",
    "    \n",
    "    Args:\n",
    "        line: A string containing one or more CSV fields\n",
    "        \n",
    "    Returns:\n",
    "        int: Number of commas between fields (field count - 1)\n",
    "    \"\"\"\n",
    "    # Use StringIO to create a file-like object from the line\n",
    "    from io import StringIO\n",
    "    \n",
    "    try:\n",
    "        # Parse the line with pandas, properly handling quoted fields\n",
    "        df = pd.read_csv(StringIO(line), \n",
    "                        quotechar='\"',\n",
    "                        header=None)\n",
    "        \n",
    "        # Return number of commas (number of fields - 1)\n",
    "        return len(df.columns) - 1\n",
    "        \n",
    "    except pd.errors.EmptyDataError:\n",
    "        # Handle empty lines\n",
    "        return 0\n",
    "    except Exception as e:\n",
    "        # Log any other parsing errors\n",
    "        print(f\"Error parsing line: {e}\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "106b2b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_complete_record(f):\n",
    "    \"\"\"Read lines until we have a complete CSV record (all quotes matched).\n",
    "    \n",
    "    Args:\n",
    "        f: File object to read from\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (complete_record, start_line, last_line, is_empty)\n",
    "        - complete_record: The assembled record with all quotes matched\n",
    "        - start_line: The line number where the record started\n",
    "        - last_line: The line number where the record ended\n",
    "        - is_empty: True if record is empty/blank\n",
    "    \"\"\"\n",
    "    current_line = ''\n",
    "    in_quotes = False\n",
    "    i = -1  # Initialize i outside the loop\n",
    "    start_line = None\n",
    "    last_line = -1\n",
    "    \n",
    "    for i, line in enumerate(f):\n",
    "        # Track the starting line number for this record:\n",
    "        if not in_quotes and not current_line:\n",
    "            # Only set start_line when:\n",
    "            # 1. We're not inside a quoted field (not mid-field)\n",
    "            # 2. We haven't started accumulating a line (new record)\n",
    "            #       (current_line = '' for new record)\n",
    "            # This ensures we get the true start of each record,\n",
    "            # even for multi-line fields\n",
    "            start_line = i\n",
    "\n",
    "        # Handle line accumulation:\n",
    "        if in_quotes:\n",
    "            # Inside quotes: append this line to our accumulated record\n",
    "            # (handles multi-line fields)\n",
    "            current_line += line\n",
    "        else:\n",
    "            # Outside quotes: start a new record\n",
    "            # (previous record was complete or this is the first line)\n",
    "            current_line = line\n",
    "            \n",
    "        # Track whether we're inside a quoted field:\n",
    "        for char in line:\n",
    "            if char == '\"':\n",
    "                # Toggle in_quotes flag when we see a quote mark\n",
    "                # - False -> True  : entering a quoted field\n",
    "                # - True  -> False : exiting a quoted field\n",
    "                in_quotes = not in_quotes\n",
    "                \n",
    "        last_line = i\n",
    "                \n",
    "        # Process record if complete:\n",
    "        if not in_quotes:\n",
    "            # All quotes are matched, so we have a complete record\n",
    "            # Strip whitespace\n",
    "            stripped_record = current_line.strip()\n",
    "            # return the record, start_line, last_line, and whether it's empty\n",
    "            return stripped_record, start_line, last_line, (stripped_record == '')\n",
    "    \n",
    "    # Handle end of file:\n",
    "    # If we get here, we've read all lines without finding a closing quote\n",
    "    # This might indicate a malformed CSV, but we'll return what we have\n",
    "    return (\n",
    "        current_line.strip(),  # The accumulated record content (if any)\n",
    "        \n",
    "        # For the start line number:\n",
    "        # - Use start_line if we found a valid record start\n",
    "        # - Fall back to i (last processed line) if start_line was never set\n",
    "        # This ensures we always return a valid line number, even in error cases\n",
    "        start_line if start_line is not None else i,\n",
    "        \n",
    "        last_line,  # The last line we processed\n",
    "        \n",
    "        # Mark as empty (True) because:\n",
    "        # 1. We reached EOF without finding a closing quote\n",
    "        # 2. This indicates no complete valid record was found\n",
    "        # 3. Helps calling code detect end of CSV section\n",
    "        # 4. Provides graceful handling of malformed CSV files\n",
    "        True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_csv_boundaries(file_path):\n",
    "    \"\"\"Find the start and end line numbers of the CSV section\"\"\"\n",
    "    start_line = 0\n",
    "    end_line = None  # Changed to None to indicate \"read to end\"\n",
    "    header_commas = None\n",
    "    last_line = -1  # Track the last line we processed\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()  # Read all lines at once\n",
    "        i = 0\n",
    "        while i < len(lines):\n",
    "            # Create a file-like object from remaining lines\n",
    "            from io import StringIO\n",
    "            remaining_lines = StringIO(''.join(lines[i:]))\n",
    "            \n",
    "            # Get next complete record (handles multi-line fields)\n",
    "            record, start_num, end_num, is_empty = get_complete_record(remaining_lines)\n",
    "            print(f\"RECORD: {record}\")\n",
    "\n",
    "            # Adjust line numbers to account for our position in the file\n",
    "            start_num += i\n",
    "            end_num += i\n",
    "            \n",
    "            # Update last line processed and position in file\n",
    "            if end_num > last_line:\n",
    "                last_line = end_num\n",
    "            i = end_num + 1  # Move past this record\n",
    "            \n",
    "            print(f\"Record from line {start_num} to {end_num} (empty: {is_empty})\")\n",
    "           \n",
    "            # Handle empty records:\n",
    "            if is_empty:\n",
    "                if header_commas is not None:  \n",
    "                    # We've already found the CSV header and data,\n",
    "                    # so this empty line marks the end of the CSV section\n",
    "                    end_line = last_line\n",
    "                    break\n",
    "                # We haven't found the header yet, so this is\n",
    "                # just a blank line in the header section - skip it\n",
    "                continue\n",
    "                \n",
    "            # Count commas in complete record\n",
    "            num_commas = count_csv_commas(record)\n",
    "            print(f\"Line {start_num}: {num_commas} commas found\")  # Debug print\n",
    "            \n",
    "            # Process record based on comma count:\n",
    "            if header_commas is None:\n",
    "                # We haven't found the CSV header yet\n",
    "                if num_commas > 0:\n",
    "                    # Found a line with commas - assume this is our header\n",
    "                    # Store the number of commas as a pattern to match\n",
    "                    # subsequent data lines against\n",
    "                    header_commas = num_commas\n",
    "                    start_line = start_num\n",
    "                    print(f\"Found header at line {start_num}\")  # Debug print\n",
    "            elif num_commas != header_commas:\n",
    "                # This line has a different number of commas than our header\n",
    "                # This indicates we've hit a footer or non-CSV section\n",
    "                end_line = last_line + 1\n",
    "                break\n",
    "                    \n",
    "    return start_line, end_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b14c66c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_csv_boundaries(file_path):\n",
    "    \"\"\"Find the start and end line numbers of the CSV section\"\"\"\n",
    "    start_line = 0\n",
    "    end_line = None\n",
    "    header_field_count = None\n",
    "    \n",
    "    with open(file_path, 'r', newline='') as f:  # newline='' is important for CSV\n",
    "        reader = csv.reader(f)\n",
    "        for i, row in enumerate(reader):\n",
    "            # Skip empty rows before header\n",
    "            if header_field_count is None and len(row) == 0:\n",
    "                continue\n",
    "                \n",
    "            # Process row based on field count\n",
    "            field_count = len(row)\n",
    "            print(f\"Line {i}: {field_count} fields found\")  # Debug\n",
    "            \n",
    "            if header_field_count is None:\n",
    "                # First non-empty row becomes our header\n",
    "                if field_count > 0:\n",
    "                    header_field_count = field_count\n",
    "                    start_line = i\n",
    "                    print(f\"Found header at line {i}\")  # Debug\n",
    "            else:\n",
    "                # Stop at first empty line or row with different field count\n",
    "                if field_count == 0 or field_count != header_field_count:\n",
    "                    end_line = i\n",
    "                    break\n",
    "                    \n",
    "    return start_line, end_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with Cigna HSA file\n",
    "file_path = \"../data/accounts/fidelity-ira-jmm.csv\"\n",
    "start_line, end_line = find_csv_boundaries(file_path)\n",
    "print(f\"\\nCSV section found from line {start_line} to {'end' if end_line is None else end_line}\")\n",
    "\n",
    "# Read the CSV section with pandas for type conversion\n",
    "data = pd.read_csv(file_path,\n",
    "                  skiprows=start_line,\n",
    "                  nrows=end_line - start_line if end_line else None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e136c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with Cigna HSA file\n",
    "file_path = \"../data/accounts/cigna-hsa-jmm.csv\"\n",
    "start_line, end_line = find_csv_boundaries(file_path)\n",
    "print(f\"\\nCSV section found from line {start_line} to {'end' if end_line is None else end_line}\")\n",
    "\n",
    "# Read the CSV section with pandas\n",
    "if end_line is None:\n",
    "    # Read to end of file\n",
    "    data = pd.read_csv(file_path,\n",
    "                      skiprows=start_line,\n",
    "                      quotechar='\"')\n",
    "else:\n",
    "    # Read specific number of rows\n",
    "    print(f\"Reading {end_line - start_line} rows\")  # Debug print\n",
    "    data = pd.read_csv(file_path,\n",
    "                      skiprows=start_line,\n",
    "                      nrows=end_line - start_line,\n",
    "                      quotechar='\"')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "619467ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# file_path = \"../data/accounts/wealthfront-ira-jsm.csv\"\n",
    "# file_path = \"../data/accounts/vanguard-ira-jmm.csv\"\n",
    "file_path = \"../data/accounts/troweprice-401k-jmm.csv\"\n",
    "# file_path = \"../data/accounts/mndcp-457b-jsm.csv\"\n",
    "# file_path = \"../data/accounts/fidelity-ira-jmm.csv\"\n",
    "# file_path = \"../data/accounts/cigna-hsa-jmm.csv\"\n",
    "\n",
    "rows = []\n",
    "with open(file_path, 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows[1:], columns=rows[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d9ab199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_header_row(row):\n",
    "    \"\"\"Check if row contains required column headers.\n",
    "    \n",
    "    Args:\n",
    "        row: List of column names to check\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if row contains required columns\n",
    "    \"\"\"\n",
    "    # Convert all column names to uppercase for case-insensitive comparison\n",
    "    cols_upper = [col.upper() for col in row]\n",
    "    \n",
    "    # Check for symbol column\n",
    "    has_symbol = any(col in cols_upper for col in ['SYMBOL', 'INVESTMENT'])\n",
    "    \n",
    "    # Check for quantity column\n",
    "    has_quantity = any(col in row for col in ['Quantity', 'Shares', 'UNIT/SHARE OWNED'])\n",
    "    \n",
    "    return has_symbol and has_quantity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8a6cc0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_csv_rows(file_path):\n",
    "    \"\"\"Read CSV file and return header and data rows.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to CSV file\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (header_row, data_rows)\n",
    "        - header_row: List of column names\n",
    "        - data_rows: List of lists containing data values\n",
    "    \"\"\"\n",
    "    header = None\n",
    "    data_rows = []\n",
    "    \n",
    "    with open(file_path, 'r', newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            if not row:  # Skip empty rows\n",
    "                continue\n",
    "                \n",
    "            if header is None:\n",
    "                # Look for header row with required columns\n",
    "                if is_header_row(row):\n",
    "                    header = row\n",
    "                    header_field_count = len(row)\n",
    "                # Skip this row if it's not the header\n",
    "                continue\n",
    "            \n",
    "            # Only include rows that match header field count\n",
    "            if len(row) == header_field_count:\n",
    "                data_rows.append(row)\n",
    "            else:\n",
    "                # Stop at first row with different field count (footer)\n",
    "                break\n",
    "                    \n",
    "    if header is None:\n",
    "        raise ValueError(\"Could not find header row with required columns\")\n",
    "        \n",
    "    return header, data_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f0c3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use the function with DataFrame constructor\n",
    "# file_path = \"../data/accounts/wealthfront-ira-jsm.csv\"\n",
    "# file_path = \"../data/accounts/vanguard-ira-jmm.csv\"\n",
    "# file_path = \"../data/accounts/troweprice-401k-jmm.csv\"\n",
    "# file_path = \"../data/accounts/mndcp-457b-jsm.csv\"\n",
    "# file_path = \"../data/accounts/fidelity-ira-jmm.csv\"\n",
    "file_path = \"../data/accounts/cigna-hsa-jmm.csv\"\n",
    "header, data_rows = read_csv_rows(file_path)\n",
    "\n",
    "# Create DataFrame with existing converters\n",
    "df = pd.DataFrame(data_rows, columns=header)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Portfolio Optimization",
   "language": "python",
   "name": "portopt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
